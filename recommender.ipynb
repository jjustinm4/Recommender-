{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommender.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhtf91oacEHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load Movies Metadata\n",
        "metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99eZV7_MWkx",
        "colab_type": "text"
      },
      "source": [
        "WeightedRating(WR)=(v/v+m⋅(R))+(m/v+m⋅(C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504rSDeHMpoB",
        "colab_type": "text"
      },
      "source": [
        "v is the number of votes for the movie;\n",
        "\n",
        "m is the minimum votes required to be listed in the chart;\n",
        "\n",
        "R is the average rating of the movie;\n",
        "\n",
        "C is the mean vote across the whole report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLsaF3YTMqpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate mean of vote average column\n",
        "C = metadata['vote_average'].mean()\n",
        "print(C)\n",
        "# Calculate the minimum number of votes required to be in the chart, m\n",
        "m = metadata['vote_count'].quantile(0.90)\n",
        "print(m)\n",
        "\n",
        "#gives 160 means number of votes should be greater than or equal to 160\n",
        "\n",
        "# Filter out all qualified movies into a new DataFrame\n",
        "\n",
        "q_movies = metadata.copy().loc[metadata['vote_count'] >= m]\n",
        "q_movies.shape\n",
        "\n",
        "#gives the shape as(4555,24)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb_8kf6_acEE",
        "colab_type": "text"
      },
      "source": [
        "Next step is to calculate the weighted rating for each movie.\n",
        "\n",
        "Define a function, weighted_rating(); with M & C as arguments\n",
        "\n",
        "Then select the vote_count(v) and vote_average(R) column from the q_movies data frame;\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWr2qVeYbHpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that computes the weighted rating of each movie\n",
        "def weighted_rating(x, m=m, C=C):\n",
        "    v = x['vote_count']\n",
        "    R = x['vote_average']\n",
        "    # Calculation based on the IMDB formula\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
        "    # Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
        "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)\n",
        "#Sort movies based on score calculated above\n",
        "q_movies = q_movies.sort_values('score', ascending=False)\n",
        "\n",
        "#Print the top 15 movies if needed\n",
        "#q_movies[['title', 'vote_count', 'vote_average', 'score']].head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKHXvos9q-3_",
        "colab_type": "text"
      },
      "source": [
        "Content-Based Recommender\n",
        "--------------------------\n",
        "Plot Description Based Recommender\n",
        "----------------------------------\n",
        "Here we try to build a system that recommends movies that are similar to a particular movie.To achieve this, we need to  compute pairwise cosine similarity scores for all movies based on their plot descriptions and recommend movies based on that similarity score threshold.The plot description is available in the overview feature in the metadata dataset. For suggesting movies based on their context we need to find the TF-IDF tokeninzer.\n",
        "*Import the Tfidf module using scikit-learn;\n",
        "*Remove stop words like 'the', 'an', etc. since they do not give any useful  information about the topic;\n",
        "*Replace not-a-number values with a blank string;\n",
        "*Construct the TF-IDF matrix on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LupMyyC9wEUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import TfIdfVectorizer from scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "#Replace NaN with an empty string\n",
        "metadata['overview'] = metadata['overview'].fillna('')\n",
        "\n",
        "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
        "tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
        "\n",
        "#Output the shape of tfidf_matrix if necessary \n",
        "#tfidf_matrix.shape\n",
        "#(45466, 75827)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "776s-erewf4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "We can use cosine similarity to calculate a numeric quantity that denotes the similarity between two movies.\n",
        "  You use the cosine similarity score since it is independent of magnitude and is relatively easy and fast to calculate \n",
        "  (especially when used in conjunction with TF-IDF scores).Since we have used the TF-IDF vectorizer, calculating the dot \n",
        "  product between each vector will directly yield the cosine similarity score. Hence use sklearn's linear_kernel() instead \n",
        "  of cosine_similarities() since it is faster."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruI7LQ8u2NX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import linear_kernel\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Compute the cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "#Construct a reverse map of indices and movie titles\n",
        "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxg1bB9j2jcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Almost final stages , do the following \n",
        "\n",
        "Get the index of the movie given its title.\n",
        "\n",
        "Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position, and the second is the similarity score.\n",
        "\n",
        "Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n",
        "\n",
        "Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n",
        "\n",
        "Return the titles corresponding to the indices of the top elements."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egpGUfCl25Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that takes in movie title as input and outputs most similar movies\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Get the pairwsie similarity scores of all movies with that movie\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar movies\n",
        "    return metadata['title'].iloc[movie_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABwNEbYk4Ssc",
        "colab_type": "text"
      },
      "source": [
        "EXAMPLE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9S6-0fO4UMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_recommendations('The Dark Knight Rises')\n",
        "1178               The Godfather: Part II\n",
        "44030    The Godfather Trilogy: 1972-1990\n",
        "1914              The Godfather: Part III\n",
        "23126                          Blood Ties\n",
        "11297                    Household Saints\n",
        "34717                   Start Liquidation\n",
        "10821                            Election\n",
        "38030            A Mother Should Be Loved\n",
        "17729                   Short Sharp Shock\n",
        "26293                  Beck 28 - Familjen"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}